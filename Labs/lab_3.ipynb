{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:rds_env]",
      "language": "python",
      "name": "conda-env-rds_env-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "lab_3",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DKrcGGhQild"
      },
      "source": [
        "# Lab 3: Exploring Fairness When Training Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SyL9goGBjya"
      },
      "source": [
        "In this lab, we will detect bias that may be introduced while training classifiers. We will mitigate this bias via pre-processing and post-processing.  \n",
        "\n",
        "This notebook has four stages in which we will: \n",
        "1. Import and split the data into train/test sets.\n",
        "2. Train a classifier to predict credit using original data with or without sensitive features.\n",
        "3. Preprocess the data using the reweighting algorithm and train a classifier using the reweighted data.\n",
        "4. Post-process the predictions using the calibrated equality of odds algorithm. For each prediction from step 2, 3, and 4, we will measure bias using fairness metrics including mean outcomes, disparate impact, false positive rate, and false negative rate. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKooNAay1wNa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f96a5ad-648f-4db6-f011-0b7dd16c2747"
      },
      "source": [
        "!pip install numba==0.48\n",
        "!pip install aif360==0.2.2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numba==0.48\n",
            "  Downloading numba-0.48.0-1-cp37-cp37m-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 30.3 MB/s \n",
            "\u001b[?25hCollecting llvmlite<0.32.0,>=0.31.0dev0\n",
            "  Downloading llvmlite-0.31.0-cp37-cp37m-manylinux1_x86_64.whl (20.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2 MB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from numba==0.48) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba==0.48) (57.4.0)\n",
            "Installing collected packages: llvmlite, numba\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "Successfully installed llvmlite-0.31.0 numba-0.48.0\n",
            "Collecting aif360==0.2.2\n",
            "  Downloading aif360-0.2.2-py2.py3-none-any.whl (56.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 56.4 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.23.3 in /usr/local/lib/python3.7/dist-packages (from aif360==0.2.2) (1.3.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from aif360==0.2.2) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from aif360==0.2.2) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from aif360==0.2.2) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.3->aif360==0.2.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.3->aif360==0.2.2) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.3->aif360==0.2.2) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->aif360==0.2.2) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->aif360==0.2.2) (1.1.0)\n",
            "Installing collected packages: aif360\n",
            "Successfully installed aif360-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyPDr4QuQilp"
      },
      "source": [
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline\n",
        "\n",
        "import random\n",
        "random.seed(6)\n",
        "\n",
        "import sys\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "from aif360.algorithms.preprocessing import Reweighing\n",
        "from aif360.datasets import GermanDataset, StandardDataset\n",
        "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
        "from aif360.algorithms.postprocessing import EqOddsPostprocessing\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY7AwOvjQilr"
      },
      "source": [
        "## Step 1: Load the data\n",
        "\n",
        "The German Credit Risk dataset contains 1000 entries with 20 categorial/symbolic attributes prepared by Prof. Hofmann. In this dataset, each entry represents a person who takes a credit by a bank. Each person is classified as good or bad credit risks according to the set of attributes. The original dataset can be found at https://archive.ics.uci.edu/ml/datasets/Statlog+%28German+Credit+Data%29"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvvwkowuQilr"
      },
      "source": [
        "### 1.1 Read in the aif360 dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW9hntAiQils"
      },
      "source": [
        "dataset_orig = GermanDataset(protected_attribute_names=['age'],           \n",
        "                             privileged_classes=[lambda x: x >= 25], \n",
        "                             features_to_drop=['personal_status', 'sex'])      # age >=25 is considered privileged\n",
        "\n",
        "# Store definitions of priviledged and unpriviledged groups\n",
        "privileged_groups = [{'age': 1}]\n",
        "unprivileged_groups = [{'age': 0}]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eYd60CSQilt"
      },
      "source": [
        "### 1.2 Split into train/test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hNDW2gWQilu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eedc2bd4-2636-4099-e868-ce3a6a01b42e"
      },
      "source": [
        "# Split original data into train and test data\n",
        "train_orig, test_orig = dataset_orig.split([0.8], shuffle=True, seed=10)\n",
        "\n",
        "# Convert to dataframes\n",
        "train_orig_df, _ = train_orig.convert_to_dataframe()\n",
        "test_orig_df, _ = test_orig.convert_to_dataframe()\n",
        "\n",
        "print(\"Train set: \", train_orig_df.shape)\n",
        "print(\"Test set: \", test_orig_df.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set:  (800, 58)\n",
            "Test set:  (200, 58)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1y1Ubj8DQilw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "5e58e5d6-dd66-4060-be10-4bbc7263d0e4"
      },
      "source": [
        "train_orig_df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d51a8c01-f428-41af-a33e-e466505924b7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>credit_amount</th>\n",
              "      <th>investment_as_income_percentage</th>\n",
              "      <th>residence_since</th>\n",
              "      <th>age</th>\n",
              "      <th>number_of_credits</th>\n",
              "      <th>people_liable_for</th>\n",
              "      <th>status=A11</th>\n",
              "      <th>status=A12</th>\n",
              "      <th>status=A13</th>\n",
              "      <th>status=A14</th>\n",
              "      <th>credit_history=A30</th>\n",
              "      <th>credit_history=A31</th>\n",
              "      <th>credit_history=A32</th>\n",
              "      <th>credit_history=A33</th>\n",
              "      <th>credit_history=A34</th>\n",
              "      <th>purpose=A40</th>\n",
              "      <th>purpose=A41</th>\n",
              "      <th>purpose=A410</th>\n",
              "      <th>purpose=A42</th>\n",
              "      <th>purpose=A43</th>\n",
              "      <th>purpose=A44</th>\n",
              "      <th>purpose=A45</th>\n",
              "      <th>purpose=A46</th>\n",
              "      <th>purpose=A48</th>\n",
              "      <th>purpose=A49</th>\n",
              "      <th>savings=A61</th>\n",
              "      <th>savings=A62</th>\n",
              "      <th>savings=A63</th>\n",
              "      <th>savings=A64</th>\n",
              "      <th>savings=A65</th>\n",
              "      <th>employment=A71</th>\n",
              "      <th>employment=A72</th>\n",
              "      <th>employment=A73</th>\n",
              "      <th>employment=A74</th>\n",
              "      <th>employment=A75</th>\n",
              "      <th>other_debtors=A101</th>\n",
              "      <th>other_debtors=A102</th>\n",
              "      <th>other_debtors=A103</th>\n",
              "      <th>property=A121</th>\n",
              "      <th>property=A122</th>\n",
              "      <th>property=A123</th>\n",
              "      <th>property=A124</th>\n",
              "      <th>installment_plans=A141</th>\n",
              "      <th>installment_plans=A142</th>\n",
              "      <th>installment_plans=A143</th>\n",
              "      <th>housing=A151</th>\n",
              "      <th>housing=A152</th>\n",
              "      <th>housing=A153</th>\n",
              "      <th>skill_level=A171</th>\n",
              "      <th>skill_level=A172</th>\n",
              "      <th>skill_level=A173</th>\n",
              "      <th>skill_level=A174</th>\n",
              "      <th>telephone=A191</th>\n",
              "      <th>telephone=A192</th>\n",
              "      <th>foreign_worker=A201</th>\n",
              "      <th>foreign_worker=A202</th>\n",
              "      <th>credit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>841</th>\n",
              "      <td>21.0</td>\n",
              "      <td>2993.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>956</th>\n",
              "      <td>30.0</td>\n",
              "      <td>3656.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>544</th>\n",
              "      <td>12.0</td>\n",
              "      <td>1255.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>8.0</td>\n",
              "      <td>1414.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>759</th>\n",
              "      <td>12.0</td>\n",
              "      <td>691.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d51a8c01-f428-41af-a33e-e466505924b7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d51a8c01-f428-41af-a33e-e466505924b7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d51a8c01-f428-41af-a33e-e466505924b7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     month  credit_amount  ...  foreign_worker=A202  credit\n",
              "841   21.0         2993.0  ...                  0.0     1.0\n",
              "956   30.0         3656.0  ...                  0.0     1.0\n",
              "544   12.0         1255.0  ...                  0.0     1.0\n",
              "173    8.0         1414.0  ...                  1.0     1.0\n",
              "759   12.0          691.0  ...                  0.0     2.0\n",
              "\n",
              "[5 rows x 58 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9G0RdfbQilw"
      },
      "source": [
        "As a reminder of what we did last week, let's calculate two fairness metrics (mean_difference and disparate_impact) on the training data (hint, use `BinarylabelDatasetMetric`):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoazzmDQQilx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b813d51-2d25-4808-e6f5-1909173859aa"
      },
      "source": [
        "# your code here\n",
        "\n",
        "train_orig_metrics = BinaryLabelDatasetMetric(train_orig, unprivileged_groups=unprivileged_groups, \n",
        "                                              privileged_groups=privileged_groups)\n",
        "print(\"Mean Difference = %f\" % train_orig_metrics.mean_difference())\n",
        "print(\"Disparate Impact = %f\" % train_orig_metrics.disparate_impact())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Difference = -0.175661\n",
            "Disparate Impact = 0.760365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vXjQtpLQily"
      },
      "source": [
        "## Step 2: Train a classifier to predict credit using the original data\n",
        "\n",
        "We will be training a logistic regression model to predict good/bad credit risk, then fine-tuning the model over a set of hyperparameters. Then, we'll see how well this basic model does on some fairness metrics. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Training and evaluating a logistic regression model \n",
        "First, we need to split our data up into the explantory variables (x) and the outcome variable (y). We will recode the outcome so that the values are 0 (= bad credit) and 1 (= good credit). This is the format that the sklearn logistic regression function expects."
      ],
      "metadata": {
        "id": "8Sl82uGvykSs"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq3P6dXAQilz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "119526e1-2219-4f20-bd49-2f84366f5d78"
      },
      "source": [
        "x_train = train_orig_df.drop(\"credit\", axis=1)\n",
        "y_train = train_orig_df.credit.replace({2:0}) \n",
        "\n",
        "x_test = test_orig_df.drop(\"credit\", axis=1)\n",
        "y_test = test_orig_df.credit.replace({2:0})\n",
        "\n",
        "print(\"Outcomes: \")\n",
        "y_train.value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outcomes: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0    565\n",
              "0.0    235\n",
              "Name: credit, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's specify the logistic regression model:"
      ],
      "metadata": {
        "id": "DZCtK28R50Hc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the logistic regression model\n",
        "initial_lr = LogisticRegression(C=0.5, penalty=\"l1\", solver='liblinear')"
      ],
      "metadata": {
        "id": "F6pTZPsq5zmX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI8BpcTIQil0"
      },
      "source": [
        "Next, we can fit our model using the training data:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "initial_lr = initial_lr.fit(x_train , y_train, sample_weight=None)"
      ],
      "metadata": {
        "id": "HAlUyiUV5y8r"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have a trained model, we should evaluate it. For now, we'll look at the AUC as well as accuracy when we use a cutoff of 0.5 (that is, predicted values over 0.5 are interpreted as good credit, and vice versa)."
      ],
      "metadata": {
        "id": "8iEnYTaYzd78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = initial_lr.predict(x_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, [pred_prob >= 0.5 for pred_prob in y_pred])\n",
        "auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "print(\"accuracy: \", accuracy)\n",
        "print(\"AUC\", auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5kEtLaM0w-m",
        "outputId": "f149b5ba-c9fd-4656-8034-cf4b5a2a02b0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:  0.725\n",
            "AUC 0.6487179487179487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mzab0o-5Qil8"
      },
      "source": [
        "### 2.2 Evaluating bias in our predictions\n",
        "\n",
        "Let's put our data back into a aif360 dataset format, so that we can use all of the fairness metrics provided by the package. For now, we'll evaluate bias on the training data. This mimics the development process we'd use in any real application.\n",
        "\n",
        "First, we'll get predicted values using the best model and attach them as a new column in the data frame. We'll use 0.5 as the threshold as before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xhb_wlGQil8"
      },
      "source": [
        "# Copy the dataset\n",
        "train_preds_df = train_orig_df.copy()\n",
        "# Calculate predicted values\n",
        "train_preds_df['credit'] = initial_lr.predict(x_train)\n",
        "# Recode the predictions so that they match the format that the dataset was originally provided in \n",
        "# (1 = good credit, 2 = bad credit)\n",
        "train_preds_df['credit'] = train_preds_df.credit.replace({0:2})"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-PK4GJ-Qil9"
      },
      "source": [
        "Then we'll create an object of the aif360 StandardDataset class. You can read more about this in the documentation:\n",
        "https://aif360.readthedocs.io/en/latest/modules/generated/aif360.datasets.StandardDataset.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5rMozURQil-"
      },
      "source": [
        "orig_aif360 = StandardDataset(train_orig_df,\n",
        "                              label_name='credit',\n",
        "                              protected_attribute_names=['age'], \n",
        "                              privileged_classes=[[1]], favorable_classes=[1])\n",
        "preds_aif360 = StandardDataset(train_preds_df,\n",
        "                               label_name='credit',\n",
        "                               protected_attribute_names=['age'], \n",
        "                               privileged_classes=[[1]], favorable_classes=[1])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QclM1irQQil_"
      },
      "source": [
        "Now, let's calculate some fairness metrics for `orig_aif360` and `preds_aif360`. Calculate the mean difference and disparate impact below (again using `BinaryLabelDatasetMetric`):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLv4s4agQimA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9be1380-b81f-4c24-b12d-191881ef7987"
      },
      "source": [
        "# your code here\n",
        "pred_metrics = BinaryLabelDatasetMetric(preds_aif360,\n",
        "                                        unprivileged_groups=unprivileged_groups, \n",
        "                                        privileged_groups=privileged_groups)\n",
        "print(\"Mean Difference = %f\" % pred_metrics.mean_difference())\n",
        "print(\"Disparate Impact = %f\" % pred_metrics.disparate_impact())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Difference = -0.302021\n",
            "Disparate Impact = 0.638215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7df8vbdGQimC"
      },
      "source": [
        "Recall from last week that we identified bias in the training data. We should therefore not find it surprising that we have bias in a model trained on that data.\n",
        "\n",
        "Now, since we have true values and predicted values, let's compare the true positive rate and false positive rate by group. This is similar to the analysis ProPublica did. We can use the `ClassificationMetric` function to do this.\n",
        "\n",
        "Note that aif360 is pretty picky about what goes into this `ClassificationMetric` class, which is the reason for all the inefficient copying of datasets above. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcQplgqVQimD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07a5c863-a7d2-46f0-9d1b-0e2b2b11e117"
      },
      "source": [
        "orig_vs_preds_metrics = ClassificationMetric(orig_aif360, preds_aif360,\n",
        "                                             unprivileged_groups=unprivileged_groups,\n",
        "                                             privileged_groups=privileged_groups)\n",
        "\n",
        "print(\"\\nError rate difference (unprivileged error rate - privileged error rate)= %f\" % orig_vs_preds_metrics.error_rate_difference())\n",
        "\n",
        "print(\"\\nFalse negative rate for privileged groups = %f\" % orig_vs_preds_metrics.false_negative_rate(privileged=True))\n",
        "print(\"False negative rate for unprivileged groups = %f\" % orig_vs_preds_metrics.false_negative_rate(privileged=False))\n",
        "print(\"False negative rate ratio = %f\" % orig_vs_preds_metrics.false_negative_rate_ratio())\n",
        "\n",
        "print(\"\\nFalse positive rate for privileged groups = %f\" % orig_vs_preds_metrics.false_positive_rate(privileged=True))\n",
        "print(\"False positive rate for unprivileged groups = %f\" % orig_vs_preds_metrics.false_positive_rate(privileged=False))\n",
        "print(\"False positive rate ratio = %f\" % orig_vs_preds_metrics.false_positive_rate_ratio())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Error rate difference (unprivileged error rate - privileged error rate)= 0.095314\n",
            "\n",
            "False negative rate for privileged groups = 0.072435\n",
            "False negative rate for unprivileged groups = 0.294118\n",
            "False negative rate ratio = 4.060458\n",
            "\n",
            "False positive rate for privileged groups = 0.580110\n",
            "False positive rate for unprivileged groups = 0.314815\n",
            "False positive rate ratio = 0.542681\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpZ6MIDRQimE"
      },
      "source": [
        "This confirms it: our model is even *more* biased than the original credit scores.  \n",
        "\n",
        "Let's try to fix that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOv7pZhwQimF"
      },
      "source": [
        "## Step 3: Train a classifier to predict credit using the original data, excluding the sensitive feature\n",
        "\n",
        "We've talked several times in class about how removing a sensitive attribute is not enough. Let's see if that's true in action."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrCaX_SXQimG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "809a1d48-1277-47ec-be5c-4f4e7cb826a4"
      },
      "source": [
        "x_train_noage = x_train.drop(\"age\", axis=1)\n",
        "x_test_noage  = x_test.drop(\"age\", axis=1)\n",
        "\n",
        "lr_noage = initial_lr.fit(x_train_noage,\n",
        "                          y_train,\n",
        "                          sample_weight=None)\n",
        "\n",
        "y_pred_noage = lr_noage.predict(x_test_noage)\n",
        "\n",
        "accuracy = accuracy_score(y_test, [pred_prob >= 0.5 for pred_prob in y_pred_noage])\n",
        "auc = roc_auc_score(y_test, y_pred_noage)\n",
        "\n",
        "print(\"accuracy: \", accuracy)\n",
        "print(\"AUC\", auc)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:  0.74\n",
            "AUC 0.6717948717948719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcN-PxAcQimH"
      },
      "source": [
        "Note that the accuracy of our model is *slightly* better than before: by excluding a feature, we've gained some accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koTe6gNlQimH"
      },
      "source": [
        "Now let's check the same bias metrics again. See the above code cell where we created `orig_vs_preds_metrics`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BedpLxvSQimH"
      },
      "source": [
        "preds_df_noage = train_orig_df.copy()\n",
        "preds_df_noage['credit'] = lr_noage.predict(x_train.drop('age', axis=1))\n",
        "preds_df_noage['credit'] = preds_df_noage.credit.replace({0:2})"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O0TMLAmQimI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f52a9f78-d651-46f7-86e0-736b1ed8cc02"
      },
      "source": [
        "# your code here\n",
        "preds_df_noage = train_orig_df.copy()\n",
        "preds_df_noage['credit'] = lr_noage.predict(x_train.drop('age', axis=1))\n",
        "preds_df_noage['credit'] = preds_df_noage.credit.replace({0:2})\n",
        "\n",
        "noage_preds_aif360 = StandardDataset(preds_df_noage, label_name = \"credit\", protected_attribute_names=[\"age\"],\n",
        "                                     privileged_classes=[[1]], favorable_classes=[1])\n",
        "\n",
        "noage_preds_metrics = BinaryLabelDatasetMetric(noage_preds_aif360,\n",
        "                                               unprivileged_groups=unprivileged_groups,\n",
        "                                               privileged_groups=privileged_groups)\n",
        "                                           \n",
        "\n",
        "print(\"Mean Difference = %f\" % noage_preds_metrics.mean_difference())\n",
        "print(\"Disparate Impact = %f\" % noage_preds_metrics.disparate_impact())\n",
        "\n",
        "\n",
        "orig_vs_noage_preds_metrics = ClassificationMetric(orig_aif360,\n",
        "                                                   noage_preds_aif360,\n",
        "                                                   unprivileged_groups=unprivileged_groups,\n",
        "                                                   privileged_groups=privileged_groups)\n",
        "\n",
        "print(\"Error rate difference (unprivileged error rate - privileged error rate) = %f\" %orig_vs_noage_preds_metrics.error_rate_difference())\n",
        "print()\n",
        "\n",
        "print(\"False negative rate for privileged groups = %f\" %orig_vs_noage_preds_metrics.false_negative_rate(privileged=True))\n",
        "print(\"False negative rate for unprivileged groups = %f\" %orig_vs_noage_preds_metrics.false_negative_rate(privileged=False))\n",
        "print(\"False negative ratio = %f\" %orig_vs_noage_preds_metrics.false_negative_rate_ratio())\n",
        "\n",
        "print()\n",
        "print(\"False positive rate for privileged groups = %f\" %orig_vs_noage_preds_metrics.false_positive_rate(privileged=True))\n",
        "print(\"False positive rate for unprivileged groups = %f\" %orig_vs_noage_preds_metrics.false_positive_rate(privileged=False))\n",
        "print(\"False positive ratio = %f\" %orig_vs_noage_preds_metrics.false_positive_rate_ratio())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Difference = -0.146453\n",
            "Disparate Impact = 0.821090\n",
            "Error rate difference (unprivileged error rate - privileged error rate) = 0.157116\n",
            "\n",
            "False negative rate for privileged groups = 0.080483\n",
            "False negative rate for unprivileged groups = 0.220588\n",
            "False negative ratio = 2.740809\n",
            "\n",
            "False positive rate for privileged groups = 0.541436\n",
            "False positive rate for unprivileged groups = 0.537037\n",
            "False positive ratio = 0.991875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx5z3o5BQimI"
      },
      "source": [
        "Scroll up -- how do these numbers for our model that doesn't use age compare to the model that *does* use it?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtC8EQmCDdPQ"
      },
      "source": [
        "**Write your comparison in this text cell:**\n",
        "The models that doesn't use age has a higher disparate impact, which means that we have mitigated bias to a certain extent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAw3h8fUQimJ"
      },
      "source": [
        "## Step 4: Preprocess the data using the reweighing algorithm, then train a classifier to predict credit using the re-weighted data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APqjkl5aQimJ"
      },
      "source": [
        "# Fit the weights to our training data\n",
        "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
        "                privileged_groups=privileged_groups)\n",
        "RW_fit = RW.fit(train_orig)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziXVHt8uQimK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b16901ae-dfec-4454-be66-870008fef40f"
      },
      "source": [
        "# Pull the actual values of the weights for the training data\n",
        "train_reweighed = RW_fit.transform(train_orig)\n",
        "training_weights = train_reweighed.instance_weights\n",
        "training_weights[:10]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.96345573, 0.96345573, 0.96345573, 0.96345573, 1.1003453 ,\n",
              "       0.96345573, 0.96345573, 1.1003453 , 0.66365741, 1.1003453 ])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_weights = initial_lr.fit(x_train_noage,\n",
        "                            y_train,\n",
        "                            sample_weight=training_weights)\n",
        "\n",
        "y_pred_weights = lr_weights.predict(x_test_noage)\n",
        "\n",
        "accuracy = accuracy_score(y_test, [pred_prob >= 0.5 for pred_prob in y_pred_weights])\n",
        "auc = roc_auc_score(y_test, y_pred_weights)\n",
        "\n",
        "print(\"accuracy: \", accuracy)\n",
        "print(\"AUC\", auc)"
      ],
      "metadata": {
        "id": "UVqNnLGf3_yH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07a314a2-92ba-4cee-85a5-888ebb536af3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:  0.755\n",
            "AUC 0.6868945868945869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvcEwpwPQimL"
      },
      "source": [
        "Our accuracy and AUC are slightly higher again. Following the process above, let's see if the fairness metrics changed. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ej_9ovOQimL"
      },
      "source": [
        "train_preds_df_weights = train_orig_df.copy()\n",
        "train_preds_df_weights['credit'] = lr_weights.predict(x_train.drop('age', axis=1))\n",
        "train_preds_df_weights['credit'] = train_preds_df_weights.credit.replace({0:2})"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQi9TyYNQimL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9016ecac-13b8-4a66-adc5-f2160e3e7d10"
      },
      "source": [
        "# your code here\n",
        "train_preds_df_weights = train_orig_df.copy()\n",
        "train_preds_df_weights['credit'] = lr_weights.predict(x_train.drop('age', axis=1))\n",
        "train_preds_df_weights['credit'] = train_preds_df_weights.credit.replace({0:2})\n",
        "\n",
        "preds_weights_aif360 = StandardDataset(train_preds_df_weights, label_name = \"credit\", protected_attribute_names=[\"age\"],\n",
        "                                     privileged_classes=[[1]], favorable_classes=[1])\n",
        "\n",
        "preds_weights_metrics = BinaryLabelDatasetMetric(preds_weights_aif360,\n",
        "                                               unprivileged_groups=unprivileged_groups,\n",
        "                                               privileged_groups=privileged_groups)\n",
        "                                           \n",
        "\n",
        "print(\"Mean Difference = %f\" % preds_weights_metrics.mean_difference())\n",
        "print(\"Disparate Impact = %f\" % preds_weights_metrics.disparate_impact())\n",
        "\n",
        "\n",
        "orig_vs_preds_weights_metrics = ClassificationMetric(orig_aif360,\n",
        "                                                   preds_weights_aif360,\n",
        "                                                   unprivileged_groups=unprivileged_groups,\n",
        "                                                   privileged_groups=privileged_groups)\n",
        "\n",
        "print(\"Error rate difference (unprivileged error rate - privileged error rate) = %f\" %orig_vs_preds_weights_metrics.error_rate_difference())\n",
        "print()\n",
        "\n",
        "print(\"False negative rate for privileged groups = %f\" %orig_vs_preds_weights_metrics.false_negative_rate(privileged=True))\n",
        "print(\"False negative rate for unprivileged groups = %f\" %orig_vs_preds_weights_metrics.false_negative_rate(privileged=False))\n",
        "print(\"False negative ratio = %f\" %orig_vs_preds_weights_metrics.false_negative_rate_ratio())\n",
        "\n",
        "print()\n",
        "print(\"False positive rate for privileged groups = %f\" %orig_vs_preds_weights_metrics.false_positive_rate(privileged=True))\n",
        "print(\"False positive rate for unprivileged groups = %f\" %orig_vs_preds_weights_metrics.false_positive_rate(privileged=False))\n",
        "print(\"False positive ratio = %f\" %orig_vs_preds_weights_metrics.false_positive_rate_ratio())\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Difference = -0.062189\n",
            "Disparate Impact = 0.924573\n",
            "Error rate difference (unprivileged error rate - privileged error rate) = 0.151869\n",
            "\n",
            "False negative rate for privileged groups = 0.074447\n",
            "False negative rate for unprivileged groups = 0.132353\n",
            "False negative ratio = 1.777822\n",
            "\n",
            "False positive rate for privileged groups = 0.546961\n",
            "False positive rate for unprivileged groups = 0.629630\n",
            "False positive ratio = 1.151141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JE9Fq1HXQimM"
      },
      "source": [
        "How do these numbers compare to the numbers above?\n",
        "This model has an even higher disparate impact than the previous models, meaning that we have managed to mitigate even more biases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7316kh6-QimM"
      },
      "source": [
        "## Step 5: Post-process the predictions from the model that we trained using weights by using the calibrated equality of odds algorithm \n",
        "\n",
        "The equality of odds algorithm is a method for adjusting predicted probabilities to ensure that the false negative rate is equal for the privileged and unprivileged groups. (This also ensures that the true positive rate is equal.) To do so, the algorithm uses the predicted probabilities and determines *two* threshold probabilities for each group. Above the upper threshold, all members of the group are assigned to the positive class, and below the lower threshold, all members of the group are assigned to the negative class. But between the two thresholds, individuals are randomly assigned a class. \n",
        "\n",
        "For details, see M. Hardt, E. Price, and N. Srebro, “Equality of Opportunity in Supervised Learning,” Conference on Neural Information Processing Systems, 2016.\n",
        "\n",
        "Which definitions of fairness does this post-processing algorithm contradict?\n",
        "\n",
        "This contradicts the statistical definition of fairness."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5aLfsvnQimN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cba00f37-d7ab-4c57-9b1f-0284359a723d"
      },
      "source": [
        "# Transform our predictions using the aif360 implementation of the equality of odds algorithm\n",
        "eq_odds = EqOddsPostprocessing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups, seed=47)\n",
        "preds_weights_eq_odds_aif360 = eq_odds.fit_predict(orig_aif360, preds_weights_aif360)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:87: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tLoFh0XERs3"
      },
      "source": [
        "Again, calculate fairness metrics:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_jogmsyQimN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "534ced88-307d-4106-f7f2-70c7690c47a9"
      },
      "source": [
        "# Calculate fairness metrics\n",
        "preds_weights_eq_odds_metrics = BinaryLabelDatasetMetric(\n",
        "    preds_weights_eq_odds_aif360,\n",
        "    unprivileged_groups=unprivileged_groups,\n",
        "    privileged_groups=privileged_groups\n",
        "  )\n",
        "\n",
        "orig_vs_preds_weights_eq_odds_metrics = ClassificationMetric(\n",
        "    orig_aif360,\n",
        "    preds_weights_eq_odds_aif360,\n",
        "    unprivileged_groups=unprivileged_groups,\n",
        "    privileged_groups=privileged_groups\n",
        "  )\n",
        "\n",
        "print(\"Mean difference = %f\" % preds_weights_eq_odds_metrics.mean_difference())\n",
        "print(\"Disparate Impact = %f\" % preds_weights_eq_odds_metrics.disparate_impact())\n",
        "\n",
        "print(\"\\nError rate difference (unprivileged error rate - privileged error rate)= %f\" % orig_vs_preds_weights_eq_odds_metrics.error_rate_difference())\n",
        "\n",
        "print(\"\\nFalse negative rate for privileged groups = %f\" % orig_vs_preds_weights_eq_odds_metrics.false_negative_rate(privileged=True))\n",
        "print(\"False negative rate for unprivileged groups = %f\" % orig_vs_preds_weights_eq_odds_metrics.false_negative_rate(privileged=False))\n",
        "print(\"False negative rate ratio = %f\" % orig_vs_preds_weights_eq_odds_metrics.false_negative_rate_ratio())\n",
        "\n",
        "print(\"\\nFalse positive rate for privileged groups = %f\" % orig_vs_preds_weights_eq_odds_metrics.false_positive_rate(privileged=True))\n",
        "print(\"False positive rate for unprivileged groups = %f\" % orig_vs_preds_weights_eq_odds_metrics.false_positive_rate(privileged=False))\n",
        "print(\"False positive rate ratio = %f\" % orig_vs_preds_weights_eq_odds_metrics.false_positive_rate_ratio())\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean difference = 0.006722\n",
            "Disparate Impact = 5.557377\n",
            "\n",
            "Error rate difference (unprivileged error rate - privileged error rate)= -0.165990\n",
            "\n",
            "False negative rate for privileged groups = 0.997988\n",
            "False negative rate for unprivileged groups = 1.000000\n",
            "False negative rate ratio = 1.002016\n",
            "\n",
            "False positive rate for privileged groups = 0.000000\n",
            "False positive rate for unprivileged groups = 0.018519\n",
            "False positive rate ratio = inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/aif360/metrics/dataset_metric.py:82: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  return metric_fun(privileged=False) / metric_fun(privileged=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTz1Iq2iQimO"
      },
      "source": [
        "What's changed in these metrics? How could the algorithm have caused that? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP-8BAK8QimO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2474d09-231a-46db-bd22-60ec8855043a"
      },
      "source": [
        "# Test how accuracy has changed\n",
        "print(\"\\nAccuracy (on training data) before equality of odds algorithm = %f\" % orig_vs_preds_weights_metrics.accuracy())\n",
        "print(\"\\nAccuracy (on training data) after equality of odds algorithm = %f\" % orig_vs_preds_weights_eq_odds_metrics.accuracy())"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy (on training data) before equality of odds algorithm = 0.776250\n",
            "\n",
            "Accuracy (on training data) after equality of odds algorithm = 0.293750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeHZskQ9Eynr"
      },
      "source": [
        "**Write your answer in this text cell:**\n",
        "The false negative rate for privileged and unprivileged groups is almost equal, and disparate impact has increase even further. This is due to the equality of odds algorithm, which uses the predicted probabilities and determines *two* threshold probabilities for each group. Above the upper threshold, all members of the group are assigned to the positive class, and below the lower threshold, all members of the group are assigned to the negative class. But between the two thresholds, individuals are randomly assigned a class. \n"
      ]
    }
  ]
}